% Chapter 1

\chapter{Introduction} % Main chapter title

\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 1. \emph{INTRODUCTION}} % This is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------

\section{Overview}
Data in many fields come to us through a process naturally described as functional. Functional data analysis (FDA) has been widely used across many disciplines and Statisticians have shown a great interest in this area of study. The very beginning of its development can be extended at least back to the attempts of Gauss and Legendre were to model and estimate the pathway of a comet \citep{legendre,gauss}. Since then, the usage of the term Functional Data Analysis was first developed by \cite{Reference1}, and it evolved with a new approach which represented the results mostly through graphical visualization. Many of the methods used in classical Statistics have their counterparts in the concept of Functional Data Analysis. Some methods are simply the extension of existing techniques in conventional Statistics while others need more than exchanging the summation, used in discrete observation, to an integration (which is a continuum). Some of the exploratory data analysis techniques adapted for Functional Data are introduced, and the variability within and between curves using those tools are explored.
\\
Functional Data Analysis provides useful tools for analyzing datasets that have points observed continuously. Functional Linear Regression Modeling, which is the functional form of Multivariate Linear Regression Modeling, is the central issue that is studied in this dissertation. Various procedures for modeling Functional Linear Regression models have been considered.  For a functional covariate and a scalar response, a principal components regression model were proposed \citep{fda.usc}. Neural network models and the use of derivatives were proposed for Functional Data. In many studies, Functional Data have mainly been expressed by \textit{Fourier Basis} or \textit{Splines Basis} and the \textit{Generalized Cross-Validation} criterion has been used to evaluate the model. \citet*{Ando2008} introduced the \textit{Radial Basis} functions which are a class of single hidden layer feedforward networks which can expressed as a linear combination of radially symmetric nonlinear basis functions. The most commonly used function in that context is tbe \textit{Gaussian Basis} function. \\
\cite{Reference1} considered a Functional Regression model where both predictor and response variables are given as functions, and thereafter \cite{olberd:ramsay} considered its modeling strategy. They estimated the model by the \textit{Least Squares} method and then evaluated it by the goodness-of-fit, $R^2$. Unfortunately, the estimated model (using \textit{Least Square} method) yielded unstable estimates. \citet*{Matsui2009} developed different estimation and evaluation methods for Functional Regression models where there is more than one functional predictor and a functional response. They used the \textit{Gaussian Basis} as it can provide a useful instrument for transforming discrete observations into functional form. In order to estimate the model parameters, a Functional Regression model is estimated using \textit{Least Square}, \textit{Maximum Likelihood} and \textit{Penalized Maximum Likelihood}. A crucial issue when modeling Functional Linear Regression Models is the choice of the smoothing parameter involved in the method of regularization. For this specific case, modified model criteria are implemented to accomodate the presence of the regularization parameter, The model criteria are: \textit{Generalized Information Criterion}, \textit{modified Akaike Information Criterion} and \textit{Generalized Bayesian Information Criterion}.     


%----------------------------------------------------------------------------------------

\section{Objectives}

The objectives of this dissertation are entirely related to the modelling of Functional Linear Regression. The objectives are summarized by the following points:

\begin{enumerate}
\item Define Functional Data Analysis and introduce some important basis functions (mainly \textit{Gaussian}, \textit{Fourier} and \textit{B-Splines}) that will help throughout the dissertation with smoothing pointwise data observed over a continuum. 
\item Provide an in-depth understanding of the different model criteria and their computations in the \texttt{R} Programming Language.
\item Cement the mathematical foundations of Functional Data Analysis by providing the relevant definitions and theorems.
\item Thoroughly provide derivations of the all different cases of Functional Linear Regression Models.
\item Simultaneously compare the three main Basis functions and the four model selection criteria through relevant illustrations.  
\end{enumerate}

\section{Scope}

Functional Linear Regression contains a broad number of topics and procedural aspects. The concepts behind many of these components of Functional Linear Regression theory are themselves vast and be considered as research topics on their own. As a result, most of these will not investigated and will be partially reviewed or will be taken as given during the presentation of theoretical concepts. An example of one such aspect which will not be investigated is the implementation of Functional Linear Regression using Functional Principal Components (FPC).\\
The scope, from a computational point of view, is to develop useful pieces of \texttt{R}-functions that may help to ally with much ease the theory of Functional Linear Regression and the practical aspects of it. The basis functions that will be reviewed are: \textit{Gaussian Basis}, \textit{Fourier Basis} and \textit{B-Splines Basis}. The model estimations that will be reviewed: \textit{Least Squares}, \textit{Maximum Likelihood} and \textit{Penalized Maximum Likelihood}. The model criteria that will be reviewed are: \textit{Generalized Information Criterion}, \textit{modified Akaike Information Criterion} and \textit{Generalized Bayesian Information Criterion}.

%----------------------------------------------------------------------------------------

\section{Layout of Document}

The layout of this document aims to provide sufficient information regarding Functional Linear Regression Modeling. The next five Chapters will cover the followings:
\begin{itemize}
\item \textbf{Chapter 2} introduces Functional Data Analysis through smoothing techniques. The different types basis functions are derived as well as their computations. There is a section that explains Model Estimation when converting discretized observations to continuous observations. The next section deals with model selection where the four model criteria that are used in Chapter 4 and Chapter 5. For each scenario, an example is provided for clearer insights. The rest of the Chapter will focus a bit more on the ways to overcome computational challenges when computing functional variables.
\item \textbf{Chapter 3} focuses on the Mathematics of Functional Data Analysis. This Chapter is very mathematical as it touches on \textit{Hilbert Spaces} and $L^2$-space. This Chapter also helps to clarify the reason why a stochastic process evolving over a continuum can be written as a linear combination of basis functions; this is called the \textit{Kahrunen-Loeve} Theorem.
\item \textbf{Chapter 4} introduces the theory of Functional Linear Regression Model. Also, the model estimations and model criteria are defined in the context of Functional Linear Regression models. The derivation of every case is clearly provided.
\item \textbf{Chapter 5} serves as an illustrative Chapter to show the computational side of Chapter 4. Towards the end of the Chapter 5, all different basis functions and the four model criteria are compared based on the \textit{Average Mean Square Error} calculated for each of them.
\item the document ends with \textbf{Chapter 6}, giving the conclusions and recommendations that were accumulated throughout the study of Functional Linear Regression Model. 
\end{itemize}

\section{Notation}

For convenience of the reader, the notation used throughout the document will be summarized here. Each item of the list will be introduced in detail in the text. This section merely provides a means of reference.
\begin{itemize}
\item FDA: \textbf{F}unctional \textbf{D}ata \textbf{A}nalysis;
\item FLRM: \textbf{F}unctional \textbf{L}inear \textbf{R}egression \textbf{M}odeling;
\item RSS: \textbf{R}esidual \textbf{S}um of \textbf{S}quares
\item mAIC: \textbf{M}odified \textbf{A}kaike \textbf{I}nformation \textbf{C}riterion;
\item GIC: \textbf{G}eneralized \textbf{I}nformation \textbf{C}riterion;
\item GBIC: \textbf{G}eneralized \textbf{B}ayesian \textbf{I}nformation \textbf{C}riterion;
\item GCV: \textbf{G}eneralized \textbf{C}ross-\textbf{V}alidation;
\item AMSE: \textbf{A}verage \textbf{M}ean \textbf{S}quared \textbf{E}rror;
\item $N$: number of functional data;
\item $K$: number of basis functions;
\item $H$: a Hilbert space;
\item $t$: one dimensional argument representing time;
\item $\mathcal{T}$ discrete grid of $t$-values;
\item $J$: cardinal of the set $\mathcal{T}$;
\item $c_{ik}$: $k^{th}$ coefficient of the basis expansion for the $i^{th}$ functional datum;
\item $\bm{C}$: matrix of coefficients, with dimensions $N \times K$
\item $\phi_k(t)$: $k^{th}$ basis function;
\item $\bm{\phi}(t)$: vector of basis functions, with length $J$;
\item $\bm{\Phi}$: matrix of basis functions, with dimensions $N \times J$;
\item $\psi_k(t)$: $k^{th}$ basis function for functional response;
\item $\bm{\psi}(t)$: vector of basis functions for functional response, with length $J$;
\item $\bm{\Psi}$: matrix of basis functions for functional response, with dimensions $N \times J$;
\item $\mu_k$: mean of $k^{th}$ value;
\item $\sigma_k$: standard deviation of $k^{th}$ value;
\item $\bm{\Sigma}$: variance covariance matrix, with dimension $K \times K$;
\item $X^T$: the transpose of matrix $X$;
\item $\overline{u}$: conjugate of vector $u$;
\item $\langle \cdot,\cdot \rangle$: inner product on a Hilbert Space;
\item $||\cdot||$: norm of the \textit{inner product};
\item $\mathcal{I}$: identity matrix;
\item $\bm{\big{1}}$: vector of ones;
\item $|\bm{X}|_{+}$: product of non-zero eigenvalues of matrix $\bm{X}$;
\item $\lambda$: smoothing parameter;
\item $\bm{\Lambda}$: matrix of regularization parameters, with dimension $\sum K^x \times \sum K^x$;
\item $\bm{\Delta}_s$: matrix representing the $s^{th}$ difference operator; 
\item $\bm{\Omega}$: penalty matrix;
\item $\odot$: Hadamart product;
\item $\otimes$: Kronecker product;
\item \texttt{R}-codes will be written in a typewriter-style font, e.g. \texttt{\texttt{Pen\_Max\_Likelihood}}
\end{itemize}

%----------------------------------------------------------------------------------------

\section{Hardware \& Software Specifications}
It is known that theory without practice is sterile and practice without theory is blind. Although this dissertation will fairly focus on introducing theory and implementing derivations of the concepts mentioned above, computation of these concepts will be mentioned in the form of examples. Most of the computations are done on the following hardware specifications:
\begin{itemize}
\item \textrm{Intel(R) Core(TM) i7-3610QM CPU 2.30GHz};
\item \textrm{8.00 GB (RAM)};
\item \textrm{Windows 7 Home Premium};
\item \textrm{64-bit Operating System};
\item \textrm{1TB 5400RPM S-ATAII Hard Drive}.
\end{itemize}
The software specifications are:
\begin{itemize}
\item \texttt{R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"};
\item \texttt{x86\_64-w64-mingw32/x64 (64-bit)};
\texttt{RStudio Version 0.98.1062};
\item all the \texttt{R} Packages are up-to-date.
\end{itemize}
Regarding the clusters specifications of High Performance Computing unit (University of Cape Town), the readers should consult their website \href{http://hex.uct.ac.za/}{http://hex.uct.ac.za/}.
